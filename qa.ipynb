{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "444df633-bbf1-4bd6-98b3-4873f86a42ba",
   "metadata": {},
   "source": [
    "# Quality assurance and automated service data review\n",
    "\n",
    "This notebook reviews published service data for common mistakes. Relies on gc-service-data-script outputs to function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b378e41d-fa09-48a8-b639-e18450cded57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import pytz\n",
    "from tqdm.notebook import tqdm  # Use tqdm.notebook for JupyterLab progress bars\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d3872ae-3955-4d82-a897-04bc4ccbf131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current datetime: 2024-11-29_12:04:52\n"
     ]
    }
   ],
   "source": [
    "# Specify date and time in correct timezone\n",
    "timezone = pytz.timezone('America/Montreal')\n",
    "current_datetime = pd.Timestamp.now(tz=timezone)\n",
    "current_datetime_str = current_datetime.strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "print(f'Current datetime: {current_datetime_str}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04bc87f5-686b-4e19-9bde-e154b2e4f428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import service inventory and service standards to dataframes\n",
    "si = pd.read_csv('si.csv', sep=';')\n",
    "ss = pd.read_csv('ss.csv', sep=';')\n",
    "\n",
    "# Extract date of generation from timestamp on last line\n",
    "date = pd.to_datetime(si.iloc[-1, 0].split(':')[1].split('_')[0])\n",
    "\n",
    "# Remove last line with datestamp from dataframes\n",
    "si = si.iloc[:-1]\n",
    "ss = ss.iloc[:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac4200ca-8e4e-417f-a153-6158a1f6fd30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0648c3a7d20a4c5ca7b57745f1dd0518",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating URIs:   0%|          | 0/5465 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All URI checks complete.\n"
     ]
    }
   ],
   "source": [
    "# Function to check if a URI's format is valid\n",
    "def is_valid_format(uri):\n",
    "    if not uri or not isinstance(uri, str):  # Ignore blank or non-string URIs\n",
    "        return False\n",
    "    return uri.startswith(('http://', 'https://'))  # Ensure valid web URL scheme\n",
    "\n",
    "# Function to check if a URI's address is valid\n",
    "def is_valid_uri(uri):\n",
    "    session = requests.Session()\n",
    "    try:\n",
    "        response = session.head(uri, timeout=10)\n",
    "        return uri, response.status_code == 200\n",
    "    except requests.RequestException:  # Handle exceptions\n",
    "        return uri, False\n",
    "\n",
    "# Load existing validation results (if the file exists)\n",
    "try:\n",
    "    previous_results_df = pd.read_csv('uri_validation_results.csv')\n",
    "    previous_validation_results = dict(zip(previous_results_df['uri'], previous_results_df['is_valid']))\n",
    "except FileNotFoundError:\n",
    "    # If no previous results file exists, start with an empty dictionary\n",
    "    previous_validation_results = {}\n",
    "\n",
    "# Define URI columns and their corresponding DataFrames\n",
    "uri_cols = {\n",
    "    'service_uri_en': si,\n",
    "    'service_uri_fr': si,\n",
    "    'standards_targets_uri_en': ss,\n",
    "    'standards_targets_uri_fr': ss,\n",
    "    'performance_results_uri_en': ss,\n",
    "    'performance_results_uri_fr': ss\n",
    "}\n",
    "\n",
    "# Step 1: Consolidate all URIs into a single list\n",
    "all_uris = pd.concat([df[col] for col, df in uri_cols.items()], ignore_index=True)\n",
    "unique_uris = all_uris.dropna().unique()  # Drop NaN and get unique URIs\n",
    "valid_format_uris = [uri for uri in unique_uris if is_valid_format(uri)]  # Filter valid formats\n",
    "\n",
    "# Step 2: Identify new URIs that need validation\n",
    "new_uris = [uri for uri in valid_format_uris if uri not in previous_validation_results]\n",
    "\n",
    "# Step 3: Validate new URIs with multithreading\n",
    "validation_results = {}\n",
    "with ThreadPoolExecutor(max_workers=1000) as executor:  # Adjust max_workers based on system capacity\n",
    "    future_to_uri = {executor.submit(is_valid_uri, uri): uri for uri in new_uris}\n",
    "    for future in tqdm(as_completed(future_to_uri), total=len(new_uris), desc=\"Validating URIs\"):\n",
    "        uri, is_valid = future.result()\n",
    "        validation_results[uri] = is_valid\n",
    "\n",
    "# Combine previous and new results\n",
    "validation_results.update(previous_validation_results)\n",
    "\n",
    "# Step 4: Map validation results back to each DataFrame column\n",
    "for column, df in uri_cols.items():\n",
    "    df[f'qa_{column}_is_valid'] = (\n",
    "        df[column]\n",
    "        .map(validation_results)\n",
    "        .astype(bool)\n",
    "        .fillna(False) # Replace NaN with False\n",
    "    )\n",
    "\n",
    "# Step 5: Save updated validation results to a CSV file\n",
    "validation_results_df = pd.DataFrame(list(validation_results.items()), columns=['uri', 'is_valid'])\n",
    "validation_results_df.to_csv('uri_validation_results.csv', index=False)\n",
    "\n",
    "print(\"All URI checks complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "952cff2c-5b01-4b80-b4c3-47c4c266f712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record is reported for a fiscal year that is incomplete or in the future.\n",
    "si['fiscal_yr_end_date'] = pd.to_datetime(si['fiscal_yr'].str.split('-').str[1]+'-04-01')\n",
    "si['qa_fiscal_yr_in_future'] = si['fiscal_yr_end_date'] >= date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a9ad843-c9aa-40ea-a1fd-2d8d8885f41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record has contradiction between client feedback channels and online interaction points for feedback\n",
    "si['qa_client_feedback_contradiction'] = (\n",
    "\n",
    "    # Service accepts client feedback via the online channel (ONL) but online issue resolution or feedback is not applicable or not activated\n",
    "    (\n",
    "        si['client_feedback_channel'].str.contains('ONL') & \n",
    "        (\n",
    "            si['os_issue_resolution_feedback'].isna() | \n",
    "            (si['os_issue_resolution_feedback'] == 'N')\n",
    "        )\n",
    "    ) |\n",
    "    # Service has not listed the online channel (ONL) for client feedback but online issue resolution or feedback is activated\n",
    "    (\n",
    "        (~si['client_feedback_channel'].str.contains('ONL')) &\n",
    "        (si['os_issue_resolution_feedback'] == 'Y')\n",
    "    )\n",
    ")\n",
    "\n",
    "# si[['client_feedback_channel', 'os_issue_resolution_feedback', 'client_feedback_contradiction']].loc[si['client_feedback_contradiction'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a72eb5a-e319-4599-b916-536b62580026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Service standards have volume but no volume indicated at service level\n",
    "ss_vol_by_service = (\n",
    "    ss.groupby(['fiscal_yr', 'service_id'])['total_volume']\n",
    "    .sum()\n",
    "    .reset_index()\n",
    "    .rename(columns={'total_volume':'total_volume_ss'})\n",
    ")\n",
    "\n",
    "si = (\n",
    "    si.merge(ss_vol_by_service, on=['fiscal_yr', 'service_id'], how='left')\n",
    "    .fillna({'total_volume_ss': 0})\n",
    ")\n",
    "\n",
    "si['qa_ss_vol_without_si_vol'] = (\n",
    "    (si['total_volume_ss'] > 0) & (si['num_applications_total'] == 0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce19d5fd-2ee5-430f-8c71-f0aee11e65af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Services that target society as a recipient type we would not expect to see specific interaction volume\n",
    "# Note that this assumption may be false\n",
    "si['qa_service_recipient_type_society_with_interactions'] = (\n",
    "    (si['service_recipient_type'] == 'SOCIETY') &\n",
    "    (si['num_applications_total'] > 0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a494f78a-85d5-4896-ba60-e6c3e4a84b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Services where 'persons' are a client type should not be 'NA' for SIN as ID\n",
    "si['qa_use_of_sin_applicable'] = (\n",
    "    (si['client_target_groups'].str.contains('PERSON')) &\n",
    "    (si['sin_usage'].isna())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0e5cc29-4a6d-4616-a1b3-29d1c5a5131e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Services where 'econom' (business) are a client type should not be 'NA' for CRA BN as ID\n",
    "si['qa_use_of_cra_bn_applicable'] = (\n",
    "    (si['client_target_groups'].str.contains('ECONOM')) &\n",
    "    (si['cra_bn_identifier_usage'].isna())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6405f82f-3a42-49f1-9a38-1a5e7536d19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the DataFrames to export to csv and their corresponding names\n",
    "csv_exports = {\n",
    "    \"si_qa\": si,\n",
    "    \"ss_qa\": ss,\n",
    "}\n",
    "\n",
    "# Loop through the dictionary\n",
    "for name, df in csv_exports.items():\n",
    "    # Generate the filename using the key (string name)\n",
    "    fn = f\"{name}.csv\"\n",
    "    \n",
    "    # Export the DataFrame to CSV\n",
    "    df.to_csv(fn, index=False, sep=';')\n",
    "    \n",
    "    # Append the timestamp at the end of the file\n",
    "    with open(fn, 'a') as timestamped_file:\n",
    "        timestamped_file.write(f\"\\nTimestamp:{current_datetime_str}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
