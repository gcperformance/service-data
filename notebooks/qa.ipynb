{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "444df633-bbf1-4bd6-98b3-4873f86a42ba",
   "metadata": {},
   "source": [
    "# Quality assurance and automated service data review\n",
    "\n",
    "This notebook reviews published service data for common mistakes. Relies on gc-service-data-script outputs to function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b378e41d-fa09-48a8-b639-e18450cded57",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests, pytz, os, re\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d3872ae-3955-4d82-a897-04bc4ccbf131",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current datetime: 2025-01-21_14:41:10\n"
     ]
    }
   ],
   "source": [
    "# Specify date and time in correct timezone\n",
    "timezone = pytz.timezone('America/Montreal')\n",
    "current_datetime = pd.Timestamp.now(tz=timezone)\n",
    "current_datetime_str = current_datetime.strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "print(f'Current datetime: {current_datetime_str}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04bc87f5-686b-4e19-9bde-e154b2e4f428",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import service inventory and service standards to dataframes\n",
    "base_dir = Path.cwd()  # Start from the current working directory\n",
    "si_file_path = base_dir.parent / \"outputs\" / \"si.csv\"\n",
    "ss_file_path = base_dir.parent / \"outputs\" / \"ss.csv\"\n",
    "\n",
    "si = pd.read_csv(si_file_path, sep=';',  na_values=[], keep_default_na=False)\n",
    "ss = pd.read_csv(ss_file_path, sep=';',  na_values=[], keep_default_na=False)\n",
    "\n",
    "qa_issues_path = base_dir.parent / 'src' / 'qa_issues_descriptions.csv'\n",
    "qa_issues_description = pd.read_csv(qa_issues_path)\n",
    "\n",
    "rbpo_file_path = base_dir.parent / 'inputs' / 'rbpo.csv'\n",
    "rbpo = pd.read_csv(rbpo_file_path)\n",
    "\n",
    "org_var_file_path = base_dir.parent / 'inputs' / 'org_var.csv'\n",
    "org_var = pd.read_csv(org_var_file_path)\n",
    "\n",
    "ifoi_en_path = base_dir.parent / 'inputs' / 'ifoi_en.csv'\n",
    "ifoi_fr_path = base_dir.parent / 'inputs' / 'ifoi_fr.csv'\n",
    "\n",
    "ifoi_en = pd.read_csv(ifoi_en_path)\n",
    "ifoi_fr = pd.read_csv(ifoi_fr_path)\n",
    "\n",
    "# Extract date of generation from timestamp on last line\n",
    "date = pd.to_datetime(si.iloc[-1, 0].split(':')[1].split('_')[0])\n",
    "\n",
    "# Remove last line with datestamp from dataframes\n",
    "si = si.iloc[:-1]\n",
    "ss = ss.iloc[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "683ec60b-6c35-4783-9b86-3153d4736327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build department name list\n",
    "dept_en = ifoi_en.iloc[:,:3]\n",
    "dept_en['department_en'] = dept_en.iloc[:,2].fillna(dept_en.iloc[:,1])\n",
    "\n",
    "dept_fr = ifoi_fr.iloc[:,:3]\n",
    "dept_fr['department_fr'] = dept_fr.iloc[:,2].fillna(dept_fr.iloc[:,1])\n",
    "\n",
    "dept = pd.merge(\n",
    "    dept_en,\n",
    "    dept_fr,\n",
    "    on='OrgID',\n",
    ")\n",
    "\n",
    "dept = dept.loc[:, ['OrgID', 'department_en', 'department_fr']]\n",
    "dept.rename(columns={'OrgID':'org_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f1ab56a-7ad8-4a45-aa9c-9a696576d276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coerce all numeric fields\n",
    "int_cols = {\n",
    "    'num_phone_enquiries': si,\n",
    "    'num_applications_by_phone': si,\n",
    "    'num_website_visits': si,\n",
    "    'num_applications_online': si,\n",
    "    'num_applications_by_mail': si,\n",
    "    'num_applications_by_email': si,\n",
    "    'num_applications_by_fax': si,\n",
    "    'num_applications_by_other': si,\n",
    "    'num_applications_total': si,\n",
    "    'volume_meeting_target': ss,\n",
    "    'total_volume': ss\n",
    "}\n",
    "\n",
    "# int_cols[column][column]\n",
    "# is int_cols[column] = dict[key],\n",
    "# then dict[key] = dataframe, \n",
    "# so dict[key][column] = dataframe[column]\n",
    "\n",
    "for column, df in int_cols.items():\n",
    "    int_cols[column][column] = pd.to_numeric(df[column], errors = 'coerce').fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c8b5c63-cdbf-45a2-92bc-a1628bd5d7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string ids to numeric, strip out prefixes\n",
    "si['service_id_numeric'] = si['service_id'].str.replace(r'^SRV', '', regex=True)\n",
    "si['service_id_numeric'] = pd.to_numeric(si['service_id_numeric'], errors = 'coerce')\n",
    "\n",
    "ss['service_standard_id_numeric'] = ss['service_standard_id'].str.replace(r'^STAN', '', regex=True)\n",
    "ss['service_standard_id_numeric'] = pd.to_numeric(ss['service_standard_id_numeric'], errors = 'coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d98fc3e1-7124-43ee-a9e8-5628faed5e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate service ID conflict\n",
    "# Step 1: Flag rows where 'service_id' is duplicated within each 'fiscal_yr'\n",
    "si['qa_duplicate_sid'] = si.duplicated(subset=['fiscal_yr', 'service_id'], keep=False)\n",
    "\n",
    "# Step 2: Get unique 'service_id's that are flagged as duplicates\n",
    "duplicate_ids = si.loc[si['qa_duplicate_sid'], 'service_id'].unique()\n",
    "\n",
    "# Step 3: Filter rows with duplicate 'service_id's and group by 'service_id' and 'department_en'\n",
    "duplicate_groups = (\n",
    "    si.loc[si['service_id'].isin(duplicate_ids), ['fiscal_yr', 'service_id', 'department_en']]\n",
    "    .groupby(['service_id', 'department_en'])['fiscal_yr']  # Count occurrences of 'fiscal_yr'\n",
    "    .nunique()  # Count unique fiscal years for each group\n",
    ")\n",
    "\n",
    "# Step 4: Identify groups with only one unique fiscal year (problematic cases)\n",
    "problematic_duplicates = duplicate_groups[duplicate_groups == 1].reset_index()\n",
    "\n",
    "# Step 5: Keep only 'service_id' and 'department_en' columns\n",
    "problematic_duplicates = problematic_duplicates[['service_id', 'department_en']]\n",
    "\n",
    "# Step 6: Create a set of tuples from 'problematic_duplicates' for efficient lookup\n",
    "problematic_set = set(zip(problematic_duplicates['service_id'], problematic_duplicates['department_en']))\n",
    "\n",
    "# Step 7: Update the 'qa_duplicate_sid' column based on whether each row matches a problematic duplicate\n",
    "si['qa_duplicate_sid'] = si.apply(\n",
    "    lambda row: (row['service_id'], row['department_en']) in problematic_set, axis=1\n",
    ")\n",
    "\n",
    "\n",
    "# check:\n",
    "# si.loc[:, ['fiscal_yr', 'department_en', 'service_id', 'qa_duplicate_sid']][si['qa_duplicate_sid']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20fb67d2-2868-4857-9926-3f361e2aec19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate Service Standard ID conflict\n",
    "# Step 1: Flag rows where 'service_standard_id' is duplicated within each 'fiscal_yr'\n",
    "ss['qa_duplicate_stdid'] = ss.duplicated(subset=['fiscal_yr', 'service_standard_id'], keep=False)\n",
    "\n",
    "# Step 2: Get unique 'service_standard_id's that are flagged as duplicates\n",
    "duplicate_ids = ss.loc[ss['qa_duplicate_stdid'], 'service_standard_id'].unique()\n",
    "\n",
    "# Step 3: Filter rows with duplicate 'service_standard_id's and group by 'service_standard_id' and 'department_en'\n",
    "duplicate_groups = (\n",
    "    ss.loc[ss['service_standard_id'].isin(duplicate_ids), ['fiscal_yr', 'service_standard_id', 'department_en']]\n",
    "    .groupby(['service_standard_id', 'department_en'])['fiscal_yr']  # Count occurrences of 'fiscal_yr'\n",
    "    .nunique()  # Count unique fiscal years for each group\n",
    ")\n",
    "\n",
    "# Step 4: Identify groups with only one unique fiscal year (problematic cases)\n",
    "problematic_duplicates = duplicate_groups[duplicate_groups == 1].reset_index()\n",
    "\n",
    "# Step 5: Keep only 'service_standard_id' and 'department_en' columns\n",
    "problematic_duplicates = problematic_duplicates[['service_standard_id', 'department_en']]\n",
    "\n",
    "# Step 6: Create a set of tuples from 'problematic_duplicates' for efficient lookup\n",
    "problematic_set = set(zip(problematic_duplicates['service_standard_id'], problematic_duplicates['department_en']))\n",
    "\n",
    "# Step 7: Update the 'qa_duplicate_sid' column based on whether each row matches a problematic duplicate\n",
    "ss['qa_duplicate_stdid'] = ss.apply(\n",
    "    lambda row: (row['service_standard_id'], row['department_en']) in problematic_set, axis=1\n",
    ")\n",
    "\n",
    "\n",
    "# check:\n",
    "# ss.loc[:, ['fiscal_yr', 'department_en', 'service_id', 'service_standard_id', 'qa_duplicate_stdid']][ss['qa_duplicate_stdid']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5314801-186c-4b39-b7ba-a21b4ea371ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify service IDs that have already been used by other departments in previous fiscal years\n",
    "si_filtered = si[['service_id', 'department_en', 'org_id', 'fiscal_yr']]\n",
    "si_filtered = si_filtered.sort_values(by=['service_id', 'fiscal_yr']).reset_index(drop=True)\n",
    "\n",
    "# Self-join to compare records\n",
    "joined_df = si_filtered.merge(si_filtered, on='service_id', suffixes=('', '_prev'))\n",
    "\n",
    "# Filter reused records\n",
    "reused_ids = joined_df[\n",
    "    (joined_df['fiscal_yr'] > joined_df['fiscal_yr_prev']) & \n",
    "    (joined_df['department_en'] != joined_df['department_en_prev'])\n",
    "]\n",
    "\n",
    "# Select the record with the latest 'fiscal_yr_prev' for each 'service_id' and 'fiscal_yr'\n",
    "reused_ids = reused_ids.loc[reused_ids.groupby(['service_id', 'fiscal_yr'])['fiscal_yr_prev'].idxmax()].reset_index(drop=True)\n",
    "\n",
    "# Identify which fiscal year and department previously used the id\n",
    "reused_ids['reused_id_from'] = reused_ids['fiscal_yr_prev']+' '+reused_ids['department_en_prev']\n",
    "\n",
    "# Create a unique key for matching\n",
    "reused_ids['key'] = (\n",
    "    reused_ids['fiscal_yr'].astype(str)+' '+\n",
    "    reused_ids['org_id'].astype(str)+' '+\n",
    "    reused_ids['service_id'].astype(str)\n",
    "    )\n",
    "\n",
    "si['key'] = (\n",
    "    si['fiscal_yr'].astype(str)+' '+\n",
    "    si['org_id'].astype(str)+' '+\n",
    "    si['service_id'].astype(str)\n",
    "    )\n",
    "\n",
    "# Map 'reused_id_from' to the original 'si' DataFrame\n",
    "reused_id_from_dict = dict(zip(reused_ids['key'], reused_ids['reused_id_from']))\n",
    "\n",
    "si['reused_id_from'] = si['key'].map(reused_id_from_dict)\n",
    "si['qa_reused_sid'] = si['reused_id_from'].notna()\n",
    "\n",
    "# Drop the temporary key column\n",
    "si = si.drop(columns=['key'])\n",
    "\n",
    "# check\n",
    "# si[['fiscal_yr', 'service_id', 'department_en', 'qa_reused_sid']][si['qa_reused_sid']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9b964c6-63af-4561-a2c3-868c0198cb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Identify service standard IDs that have already been used by other departments in previous fiscal years\n",
    "# ss_filtered = ss[['service_standard_id', 'department_en', 'org_id', 'fiscal_yr']]\n",
    "# ss_filtered = ss_filtered.sort_values(by=['service_standard_id', 'fiscal_yr']).reset_index(drop=True)\n",
    "\n",
    "# # Self-join to compare records\n",
    "# joined_df = ss_filtered.merge(ss_filtered, on='service_standard_id', suffixes=('', '_prev'))\n",
    "\n",
    "# # Filter reused records\n",
    "# reused_ids = joined_df[\n",
    "#     (joined_df['fiscal_yr'] > joined_df['fiscal_yr_prev']) & \n",
    "#     (joined_df['department_en'] != joined_df['department_en_prev'])\n",
    "# ]\n",
    "\n",
    "# # Select the record with the latest 'fiscal_yr_prev' for each 'service_standard_id' and 'fiscal_yr'\n",
    "# reused_ids = reused_ids.loc[reused_ids.groupby(['service_standard_id', 'fiscal_yr'])['fiscal_yr_prev'].idxmax()].reset_index(drop=True)\n",
    "\n",
    "# # Identify which fiscal year and department previously used the id\n",
    "# reused_ids['reused_id_from'] = reused_ids['fiscal_yr_prev']+' '+reused_ids['department_en_prev']\n",
    "\n",
    "# # Create a unique key for matching\n",
    "# reused_ids['key'] = reused_ids['fiscal_yr']+' '+reused_ids['org_id']+' '+reused_ids['service_standard_id']\n",
    "# ss['key'] = ss['fiscal_yr']+' '+ss['org_id']+' '+ss['service_standard_id']\n",
    "\n",
    "# # Map 'reused_id_from' to the original 'si' DataFrame\n",
    "# reused_id_from_dict = dict(zip(reused_ids['key'], reused_ids['reused_id_from']))\n",
    "\n",
    "# ss['reused_id_from'] = ss['key'].map(reused_id_from_dict)\n",
    "# ss['qa_reused_stdid'] = ss['reused_id_from'].notna()\n",
    "\n",
    "# # Drop the temporary key column\n",
    "# ss = ss.drop(columns=['key'])\n",
    "\n",
    "# #check\n",
    "# #ss[['fiscal_yr', 'service_id', 'service_standard_id', 'department_en', 'qa_reused_stdid']][ss['qa_reused_stdid']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "952cff2c-5b01-4b80-b4c3-47c4c266f712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record is reported for a fiscal year that is incomplete or in the future.\n",
    "si['fiscal_yr_end_date'] = pd.to_datetime(si['fiscal_yr'].str.split('-').str[1]+'-04-01')\n",
    "si['qa_si_fiscal_yr_in_future'] = si['fiscal_yr_end_date'] >= date\n",
    "\n",
    "ss['fiscal_yr_end_date'] = pd.to_datetime(ss['fiscal_yr'].str.split('-').str[1]+'-04-01')\n",
    "ss['qa_ss_fiscal_yr_in_future'] = ss['fiscal_yr_end_date'] >= date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a9ad843-c9aa-40ea-a1fd-2d8d8885f41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record has contradiction between client feedback channels and online interaction points for feedback\n",
    "si['qa_client_feedback_contradiction'] = (\n",
    "\n",
    "    # Service accepts client feedback via the online channel (ONL) but online issue resolution or feedback is not applicable or not activated\n",
    "    (\n",
    "        si['client_feedback_channel'].str.contains('ONL') & \n",
    "        (\n",
    "            si['os_issue_resolution_feedback'].isna() | \n",
    "            (si['os_issue_resolution_feedback'] == 'N')\n",
    "        )\n",
    "    ) |\n",
    "    # Service has not listed the online channel (ONL) for client feedback but online issue resolution or feedback is activated\n",
    "    (\n",
    "        (~si['client_feedback_channel'].str.contains('ONL')) &\n",
    "        (si['os_issue_resolution_feedback'] == 'Y')\n",
    "    )\n",
    ")\n",
    "\n",
    "# si[['client_feedback_channel', 'os_issue_resolution_feedback', 'client_feedback_contradiction']].loc[si['client_feedback_contradiction'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a72eb5a-e319-4599-b916-536b62580026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Service standards have volume but no volume indicated at service level\n",
    "ss_vol_by_service = (\n",
    "    ss.groupby(['fiscal_yr', 'service_id'])['total_volume']\n",
    "    .sum()\n",
    "    .reset_index()\n",
    "    .rename(columns={'total_volume':'total_volume_ss'})\n",
    ")\n",
    "\n",
    "si = si.merge(ss_vol_by_service, on=['fiscal_yr', 'service_id'], how='left').fillna(0)\n",
    "\n",
    "si['qa_ss_vol_without_si_vol'] = (\n",
    "    (si['total_volume_ss'] > 0) & (si['num_applications_total'] == 0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8aff6424-e048-44a8-beea-4881a167e5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Service standard reports no volume\n",
    "ss['qa_no_ss_volume'] = (ss['total_volume'] == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce19d5fd-2ee5-430f-8c71-f0aee11e65af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Services that target society as a recipient type we would not expect to see specific interaction volume\n",
    "# Note that this assumption may be false\n",
    "si['num_applications_total'] = pd.to_numeric(si['num_applications_total'], errors = 'coerce').fillna(0).astype(int)\n",
    "\n",
    "si['qa_service_recipient_type_society_with_interactions'] = (\n",
    "    (si['service_recipient_type'] == 'SOCIETY') &\n",
    "    (si['num_applications_total'] > 0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a494f78a-85d5-4896-ba60-e6c3e4a84b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Services where 'persons' are a client type should not be 'NA' for SIN as ID\n",
    "si['qa_use_of_sin_applicable'] = (\n",
    "    (si['client_target_groups'].str.contains('PERSON')) &\n",
    "    (si['sin_usage'] == 'NA')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0e5cc29-4a6d-4616-a1b3-29d1c5a5131e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Services where 'econom' (business) are a client type should not be 'NA' for CRA BN as ID\n",
    "si['qa_use_of_cra_bn_applicable'] = (\n",
    "    (si['client_target_groups'].str.contains('ECONOM')) &\n",
    "    (si['cra_bn_identifier_usage'] == 'NA')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a15845cf-64e3-42d8-b883-c189fb7e31a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Services that reported a different department's program\n",
    "\n",
    "# Filter and clean rbpo DataFrame to get a clean list of programs and departments\n",
    "rbpo_filtered = (\n",
    "    rbpo[['organization', 'program_id']]  # Select relevant columns\n",
    "    .merge(org_var, left_on='organization', right_on='org_name_variant', how='left')  # Merge with org_var\n",
    "    .drop_duplicates()  # Remove duplicate rows\n",
    ")\n",
    "\n",
    "# Filter out internal programs containing 'ISS'\n",
    "rbpo_filtered['internal_program'] = rbpo_filtered['program_id'].str.contains('ISS')\n",
    "rbpo_filtered = rbpo_filtered[~rbpo_filtered['internal_program']]  # Keep only non-internal programs\n",
    "rbpo_filtered = rbpo_filtered[['program_id', 'org_id']]  # Keep only necessary columns\n",
    "\n",
    "rbpo_filtered['org_id']= rbpo_filtered['org_id'].astype(str)\n",
    "\n",
    "# Prepare si_prog DataFrame\n",
    "si_prog = si.loc[:,['fiscal_yr', 'service_id', 'program_id', 'org_id']]  # Select relevant columns\n",
    "si_prog['org_id'] = si_prog['org_id'].astype(str)\n",
    "\n",
    "\n",
    "# Split and explode program_id to handle multiple entries per cell\n",
    "si_prog['program_id'] = si_prog['program_id'].str.split(',')\n",
    "si_prog = si_prog.explode('program_id')\n",
    "\n",
    "# Filter out internal programs containing 'ISS'\n",
    "si_prog['internal_program'] = si_prog['program_id'].str.contains('ISS') \n",
    "si_prog = si_prog[~si_prog['internal_program']]  # Keep only non-internal programs\n",
    "\n",
    "#Join si_prog with rbpo_filtered (program list) on program_id\n",
    "si_prog = si_prog.merge(rbpo_filtered, on='program_id', how='left', suffixes=('_si', '_prog'))\n",
    "si_prog['qa_program_from_wrong_org'] = si_prog['org_id_si'] != si_prog['org_id_prog'] # Identify rows where org_id mismatch occurs\n",
    "si_prog = si_prog[si_prog['qa_program_from_wrong_org']]  # Keep only mismatched rows\n",
    "si_prog = si_prog[si_prog['program_id'] != ''] # Remove rows with empty program_id\n",
    "\n",
    "dept['org_id'] = dept['org_id'].astype(str)\n",
    "\n",
    "# Merge si_prog with department information\n",
    "si_prog = si_prog.merge(dept, left_on='org_id_prog', right_on='org_id', how='left')\n",
    "\n",
    "# Create a field describing the correct organization associated to the program id\n",
    "si_prog['program_correct_org'] = (\n",
    "    si_prog['program_id'] + ': ' + si_prog['department_en'] + '/' + si_prog['department_fr']\n",
    ")\n",
    "\n",
    "collapsed_si_prog = (\n",
    "        si_prog.groupby(['fiscal_yr', 'service_id', 'org_id_si'], as_index=False)\n",
    "        .agg({'program_correct_org': lambda x: '<>'.join(sorted(x))})\n",
    "    )\n",
    "\n",
    "collapsed_si_prog.rename(columns={'org_id_si': 'org_id'}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b226ad7d-e5b4-4ffc-89c6-5f62450148de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8911 entries, 0 to 8910\n",
      "Data columns (total 65 columns):\n",
      " #   Column                                               Non-Null Count  Dtype         \n",
      "---  ------                                               --------------  -----         \n",
      " 0   fiscal_yr                                            8911 non-null   object        \n",
      " 1   service_id                                           8911 non-null   object        \n",
      " 2   service_name_en                                      8911 non-null   object        \n",
      " 3   service_name_fr                                      8911 non-null   object        \n",
      " 4   service_description_en                               8911 non-null   object        \n",
      " 5   service_description_fr                               8911 non-null   object        \n",
      " 6   service_type                                         8911 non-null   object        \n",
      " 7   service_recipient_type                               8911 non-null   object        \n",
      " 8   service_scope                                        8911 non-null   object        \n",
      " 9   client_target_groups                                 8911 non-null   object        \n",
      " 10  program_name_en                                      8911 non-null   object        \n",
      " 11  program_name_fr                                      8911 non-null   object        \n",
      " 12  client_feedback_channel                              8911 non-null   object        \n",
      " 13  service_fee                                          8911 non-null   object        \n",
      " 14  last_GBA                                             8911 non-null   object        \n",
      " 15  ident_platform                                       8911 non-null   object        \n",
      " 16  ident_platform_comments                              8911 non-null   object        \n",
      " 17  os_account_registration                              8911 non-null   object        \n",
      " 18  os_authentication                                    8911 non-null   object        \n",
      " 19  os_application                                       8911 non-null   object        \n",
      " 20  os_decision                                          8911 non-null   object        \n",
      " 21  os_issuance                                          8911 non-null   object        \n",
      " 22  os_issue_resolution_feedback                         8911 non-null   object        \n",
      " 23  os_comments_client_interaction_en                    8911 non-null   object        \n",
      " 24  os_comments_client_interaction_fr                    8911 non-null   object        \n",
      " 25  how_has_the_service_been_assessed_for_accessibility  8911 non-null   object        \n",
      " 26  last_service_review                                  8911 non-null   object        \n",
      " 27  last_service_improvement                             8911 non-null   object        \n",
      " 28  sin_usage                                            8911 non-null   object        \n",
      " 29  cra_bn_identifier_usage                              8911 non-null   object        \n",
      " 30  num_phone_enquiries                                  8911 non-null   int64         \n",
      " 31  num_applications_by_phone                            8911 non-null   int64         \n",
      " 32  num_website_visits                                   8911 non-null   int64         \n",
      " 33  num_applications_online                              8911 non-null   int64         \n",
      " 34  num_applications_in_person                           8911 non-null   object        \n",
      " 35  num_applications_by_mail                             8911 non-null   int64         \n",
      " 36  num_applications_by_email                            8911 non-null   int64         \n",
      " 37  num_applications_by_fax                              8911 non-null   int64         \n",
      " 38  num_applications_by_other                            8911 non-null   int64         \n",
      " 39  special_remarks_en                                   8911 non-null   object        \n",
      " 40  special_remarks_fr                                   8911 non-null   object        \n",
      " 41  service_uri_en                                       8911 non-null   object        \n",
      " 42  service_uri_fr                                       8911 non-null   object        \n",
      " 43  num_applications_total                               8911 non-null   int64         \n",
      " 44  org_id                                               8911 non-null   object        \n",
      " 45  department_en                                        8911 non-null   object        \n",
      " 46  department_fr                                        8911 non-null   object        \n",
      " 47  program_id                                           8911 non-null   object        \n",
      " 48  automated_decision_system_description_en             8911 non-null   object        \n",
      " 49  automated_decision_system                            8911 non-null   object        \n",
      " 50  automated_decision_system_description_fr             8911 non-null   object        \n",
      " 51  service_id_numeric                                   8911 non-null   int64         \n",
      " 52  qa_duplicate_sid                                     8911 non-null   bool          \n",
      " 53  reused_id_from                                       8911 non-null   object        \n",
      " 54  qa_reused_sid                                        8911 non-null   bool          \n",
      " 55  fiscal_yr_end_date                                   8911 non-null   datetime64[ns]\n",
      " 56  qa_si_fiscal_yr_in_future                            8911 non-null   bool          \n",
      " 57  qa_client_feedback_contradiction                     8911 non-null   bool          \n",
      " 58  total_volume_ss                                      8911 non-null   float64       \n",
      " 59  qa_ss_vol_without_si_vol                             8911 non-null   bool          \n",
      " 60  qa_service_recipient_type_society_with_interactions  8911 non-null   bool          \n",
      " 61  qa_use_of_sin_applicable                             8911 non-null   bool          \n",
      " 62  qa_use_of_cra_bn_applicable                          8911 non-null   bool          \n",
      " 63  program_correct_org                                  8911 non-null   object        \n",
      " 64  qa_program_from_wrong_org                            8911 non-null   bool          \n",
      "dtypes: bool(9), datetime64[ns](1), float64(1), int64(10), object(44)\n",
      "memory usage: 3.9+ MB\n"
     ]
    }
   ],
   "source": [
    "si=si.merge(collapsed_si_prog, on=['fiscal_yr', 'service_id', 'org_id'], how='left')\n",
    "si['qa_program_from_wrong_org'] = ~(si['program_correct_org'].isna())\n",
    "si['program_correct_org'] = si['program_correct_org'].fillna(False)\n",
    "\n",
    "si.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8327a5-e413-487d-9c27-9270d69e9368",
   "metadata": {},
   "source": [
    "### Clean QA report\n",
    "\n",
    "In order to have a clean report of issues to send to departments & agencies, the following bit of script re-organizes the information in the qa columns to a simple report for 2023-2024 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a732e1a-7921-4963-bf5d-951256c89127",
   "metadata": {},
   "outputs": [],
   "source": [
    "si_qa_cols = si.columns.str.startswith('qa')\n",
    "ss_qa_cols = ss.columns.str.startswith('qa')\n",
    "\n",
    "critical_si_qa_cols = [\n",
    "    'qa_duplicate_sid',\n",
    "    'qa_si_fiscal_yr_in_future',\n",
    "    'qa_ss_vol_without_si_vol',\n",
    "    'qa_reused_sid'\n",
    "]\n",
    "\n",
    "critical_ss_qa_cols = [\n",
    "    'qa_duplicate_stdid',\n",
    "    'qa_no_ss_volume',\n",
    "    'qa_ss_fiscal_yr_in_future'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b2a2a48-5e2b-4a17-a9c1-9738969f51d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing SI QA report\n",
    "si_report_cols = [\n",
    "    'department_en',\n",
    "    'fiscal_yr', \n",
    "    'service_id', \n",
    "    'service_name_en', \n",
    "    'service_name_fr',\n",
    "    'num_applications_total',\n",
    "    'total_volume_ss',\n",
    "    'reused_id_from'\n",
    "]\n",
    "\n",
    "si_qa_report = pd.melt(si, id_vars=si_report_cols, value_vars=critical_si_qa_cols, var_name='issue', value_name='issue_present')\n",
    "\n",
    "si_qa_report = si_qa_report[(si_qa_report['issue_present'] & si_qa_report['fiscal_yr'].isin(['2023-2024', '2024-2025']))]\n",
    "\n",
    "si_qa_report = pd.merge(\n",
    "    si_qa_report, \n",
    "    qa_issues_description.loc[:, [\n",
    "        'qa_field_name', \n",
    "        'description_en', \n",
    "        'action_en',\n",
    "        'description_fr',\n",
    "        'action_fr'\n",
    "    ]], \n",
    "    left_on='issue', \n",
    "    right_on='qa_field_name', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "si_qa_report = si_qa_report.drop(columns=['issue_present', 'qa_field_name'])\n",
    "\n",
    "si_qa_report = si_qa_report.sort_values(by=['department_en', 'service_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86be24c1-5e63-443b-94de-4cd67677ac25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing SS QA report\n",
    "ss_report_cols = [\n",
    "    'department_en',\n",
    "    'fiscal_yr', \n",
    "    'service_id', \n",
    "    'service_name_en', \n",
    "    'service_name_fr',\n",
    "    'service_standard_id',\n",
    "    'service_standard_en',\n",
    "    'service_standard_fr',\n",
    "    'volume_meeting_target',\n",
    "    'total_volume',\n",
    "]\n",
    "\n",
    "ss_qa_report = pd.melt(ss, id_vars=ss_report_cols, value_vars=critical_ss_qa_cols, var_name='issue', value_name='issue_present')\n",
    "\n",
    "ss_qa_report = ss_qa_report[(ss_qa_report['issue_present'] & ss_qa_report['fiscal_yr'].isin(['2023-2024', '2024-2025']))]\n",
    "\n",
    "ss_qa_report = pd.merge(\n",
    "    ss_qa_report, \n",
    "    qa_issues_description.loc[:, [\n",
    "        'qa_field_name', \n",
    "        'description_en', \n",
    "        'action_en',\n",
    "        'description_fr',\n",
    "        'action_fr'\n",
    "    ]], \n",
    "    left_on='issue', \n",
    "    right_on='qa_field_name', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "ss_qa_report = ss_qa_report.drop(columns=['issue_present', 'qa_field_name'])\n",
    "\n",
    "ss_qa_report = ss_qa_report.sort_values(by=['department_en', 'service_id', 'service_standard_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228610c9-ad2c-4efa-b03e-fe9b96bfa423",
   "metadata": {},
   "source": [
    "## Export data to CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da710304-2e7a-4b57-bf46-372aa52d5154",
   "metadata": {},
   "source": [
    "# Define the DataFrames to export to csv and their corresponding names\n",
    "csv_exports = {\n",
    "    \"si_qa\": si,\n",
    "    \"ss_qa\": ss,\n",
    "    \"si_qa_report\": si_qa_report,\n",
    "    \"ss_qa_report\": ss_qa_report\n",
    "}\n",
    "\n",
    "# Loop through the dictionary\n",
    "for name, df in csv_exports.items():\n",
    "    # Generate the filename using the key (string name)\n",
    "    fn = f\"{name}.csv\"\n",
    "    \n",
    "    # Export the DataFrame to CSV\n",
    "    df.to_csv(fn, index=False, sep=';')\n",
    "    \n",
    "    # Append the timestamp at the end of the file\n",
    "    with open(fn, 'a') as timestamped_file:\n",
    "        timestamped_file.write(f\"\\nTimestamp:{current_datetime_str}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
