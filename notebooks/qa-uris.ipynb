{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "444df633-bbf1-4bd6-98b3-4873f86a42ba",
   "metadata": {},
   "source": [
    "# Quality assurance and automated service data review: URIs only\n",
    "\n",
    "This notebook reviews published service data for issues with reported URIs. Relies on gc-service-data-script outputs to function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b378e41d-fa09-48a8-b639-e18450cded57",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests, pytz, os, re\n",
    "from tqdm.notebook import tqdm  # Use tqdm.notebook for JupyterLab progress bars\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3872ae-3955-4d82-a897-04bc4ccbf131",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Specify date and time in correct timezone\n",
    "timezone = pytz.timezone('America/Montreal')\n",
    "current_datetime = pd.Timestamp.now(tz=timezone)\n",
    "current_datetime_str = current_datetime.strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "print(f'Current datetime: {current_datetime_str}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bc87f5-686b-4e19-9bde-e154b2e4f428",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import service inventory and service standards to dataframes\n",
    "si = pd.read_csv('si.csv', sep=';',  na_values=[], keep_default_na=False)\n",
    "ss = pd.read_csv('ss.csv', sep=';',  na_values=[], keep_default_na=False)\n",
    "\n",
    "# Extract date of generation from timestamp on last line\n",
    "date = pd.to_datetime(si.iloc[-1, 0].split(':')[1].split('_')[0])\n",
    "\n",
    "# Remove last line with datestamp from dataframes\n",
    "si = si.iloc[:-1]\n",
    "ss = ss.iloc[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71d2a70-3ca0-44f6-8c4b-d02589e9d720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if a URI's format is a problem\n",
    "def is_problem_format(uri):\n",
    "    # Normalize URI by converting to string and stripping whitespace\n",
    "    uri = str(uri).strip()\n",
    "\n",
    "    # Check for multiple occurrences of 'http' or 'https'\n",
    "    if uri.count('http://') > 1 or uri.count('https://') > 1:\n",
    "        return True  # Problematic if more than one scheme\n",
    "\n",
    "    # Check if input starts with valid schemes\n",
    "    if not uri.startswith(('http://', 'https://')):\n",
    "        return True  # Problematic if it does not start with a valid scheme\n",
    "\n",
    "    # Check for invalid characters\n",
    "    invalid_characters_pattern = r'[^a-zA-Z0-9\\-._~:/?#@!$&\\'()*+,;=%]'\n",
    "    if re.search(invalid_characters_pattern, uri):\n",
    "        return True  # Problematic if invalid characters are found\n",
    "\n",
    "    return False  # No problem\n",
    "\n",
    "\n",
    "# Function to check if a URI's address is a problem\n",
    "def is_problem_uri(uri):\n",
    "    session = requests.Session()\n",
    "    try:\n",
    "        response = session.head(uri, allow_redirects=True, timeout=60)\n",
    "        return uri, response.status_code != 200, response.status_code\n",
    "    except requests.RequestException as e:\n",
    "        return uri, True, str(e)\n",
    "\n",
    "# Consolidate all URIs from DataFrames\n",
    "uri_cols = {\n",
    "    'service_uri_en': si,\n",
    "    'service_uri_fr': si,\n",
    "    'standards_targets_uri_en': ss,\n",
    "    'standards_targets_uri_fr': ss,\n",
    "    'performance_results_uri_en': ss,\n",
    "    'performance_results_uri_fr': ss\n",
    "}\n",
    "\n",
    "# Set up dictionaries to store validation results and descriptions of issues. \n",
    "# Keys will be URIs, values will be results or details\n",
    "validation_results = {}\n",
    "details = {}\n",
    "\n",
    "# Generate a list of unique URIs to check\n",
    "all_uris = pd.concat([df[col] for col, df in uri_cols.items()], ignore_index=True)\n",
    "print(f'total uri records: {len(all_uris)}')\n",
    "\n",
    "unique_uris = all_uris.dropna().sort_values().unique()\n",
    "print(f'unique uris: {len(unique_uris)}')\n",
    "\n",
    "# Filter out problematic formats so we don't validate them with requests\n",
    "problem_format_uris = [uri for uri in unique_uris if is_problem_format(uri)]\n",
    "print(f'problem format uris: {len(problem_format_uris)}')\n",
    "\n",
    "# All problem format URIs are assigned the same description\n",
    "for uri in problem_format_uris:\n",
    "#    print(f'problem format: {uri}')\n",
    "    validation_results[uri] = True\n",
    "    details[uri] = \"Incorrect URI format\"\n",
    "\n",
    "# Remove problematic format URIs from unique_uris\n",
    "unique_uris = [uri for uri in unique_uris if uri not in problem_format_uris]\n",
    "print(f'valid format uris: {len(unique_uris)}')\n",
    "\n",
    "# Use ThreadPoolExecutor for parallel validation of remaining URIs\n",
    "with ThreadPoolExecutor(max_workers=1000) as executor:\n",
    "    results = executor.map(is_problem_uri, unique_uris)\n",
    "\n",
    "# Process results from executor.map\n",
    "    for uri, is_problem, detail in results:\n",
    "#        print(f'{is_problem}, {detail}: {uri}')\n",
    "        validation_results[uri] = is_problem\n",
    "        details[uri] = detail\n",
    "\n",
    "print('done checks.')\n",
    "\n",
    "# Filter validation_results for only results with errors:\n",
    "filtered_results = {uri: is_problem for uri, is_problem in validation_results.items() if is_problem}\n",
    "\n",
    "print(f'problem uris: {len(filtered_results)}')\n",
    "\n",
    "# Save updated validation results\n",
    "filtered_results_df = pd.DataFrame(\n",
    "    [(uri, is_problem) for uri, is_problem in filtered_results.items()],\n",
    "    columns=['uri', 'is_problem']\n",
    ")\n",
    "\n",
    "# Map validation results to DataFrames\n",
    "for column, df in uri_cols.items():\n",
    "    # Add validation status\n",
    "    df = df.merge(filtered_results_df, how='left', left_on=column, right_on='uri')\n",
    "    uri_cols[column][f'qa_{column}_is_problem'] = df['is_problem'].astype(bool).fillna(False)\n",
    "    \n",
    "print('Dataframes updated')\n",
    "\n",
    "\n",
    "filtered_results_df.to_csv('uri_validation_errors.csv', index=False)\n",
    "print('Results saved')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
