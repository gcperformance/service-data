name: Process and Release Service Data

on:
  push:
    branches:
      - master  # Run on all pushes to master
  pull_request:
    branches:
      - master  # Run on all PRs targeting master
  schedule:
    - cron: '0 0 * * 2'  # weekly runs on tuesday morning (1) at midnight
  workflow_dispatch:  # Allow manual triggers

jobs:
  generate-files:
    runs-on: ubuntu-latest
    permissions:
      contents: write  # Needed for creating releases
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install requirements for python
        run: pip install -r requirements.txt

      - name: Get current date and commit hash
        id: metadata
        run: |
          echo "date=$(date +'%Y-%m-%d')" >> $GITHUB_OUTPUT
          echo "commit_hash=$(git rev-parse --short HEAD)" >> $GITHUB_OUTPUT
          echo "time=$(date +'%H:%M')" >> $GITHUB_OUTPUT

      - name: Detect Snapshot Dates
        id: detect_snapshots
        run: |
          # Find all unique snapshot date folders in inputs/snapshots/ and outputs/snapshots/
          SNAPSHOT_DATES=$(find inputs/snapshots/ -mindepth 1 -maxdepth 1 -type d -printf "%f\n" | sort -u)
          
          echo "Found snapshots:"
          echo "$SNAPSHOT_DATES"

          # Store in environment variable (space-separated list)
          echo "snapshot_dates=$SNAPSHOT_DATES" >> $GITHUB_ENV

      - name: Run main.py for live data
        run: python main.py

      - name: Run main.py for Each Snapshot Date
        run: |
          if [ -n "${{ env.snapshot_dates }}" ]; then
            IFS=' ' read -r -a SNAPSHOT_ARRAY <<< "${{ env.snapshot_dates }}"
            for SNAPSHOT_DATE in "${SNAPSHOT_ARRAY[@]}"; do
              echo "Running main.py for snapshot: $SNAPSHOT_DATE"
              python main.py --snapshot "$SNAPSHOT_DATE"
            done
          else
            echo "No snapshots found. Skipping snapshot processing."
          fi


      - name: Create SQLite database
        run: python src/create_sqlite.py

      - name: Prepare Files for Release
        id: prepare_files
        run: |
          mkdir -p snapshots_release
          mkdir -p live_data_release

          echo "Copying live data files..."
          find outputs inputs -type f -name "*.csv" ! -path "*/snapshots/*" -exec cp {} live_data_release/ \; -exec echo "Copied: {}" \;

          if [ -n "${{ env.snapshot_dates }}" ]; then
            for SNAPSHOT_DATE in ${{ env.snapshot_dates }}; do
              SNAPSHOT_DIR="snapshots_${SNAPSHOT_DATE}"
              mkdir -p "snapshots_release/$SNAPSHOT_DIR"
              echo "Processing snapshot: $SNAPSHOT_DATE"

              if [ -d "inputs/snapshots/$SNAPSHOT_DATE" ]; then
                echo "Copying from inputs/snapshots/$SNAPSHOT_DATE"
                find inputs/snapshots/$SNAPSHOT_DATE -type f -name "*.csv" -exec cp {} "snapshots_release/$SNAPSHOT_DIR/" \;
              fi

              if [ -d "outputs/snapshots/$SNAPSHOT_DATE" ]; then
                echo "Copying from outputs/snapshots/$SNAPSHOT_DATE"
                find outputs/snapshots/$SNAPSHOT_DATE -type f -name "*.csv" -exec cp {} "snapshots_release/$SNAPSHOT_DIR/" \;
              fi
            done
          else
            echo "No snapshots found. Skipping snapshot processing."
          fi

          echo "snapshot_dir=snapshots_release" >> $GITHUB_ENV
          echo "live_data_dir=live_data_release" >> $GITHUB_ENV

      - name: Create Release
        uses: softprops/action-gh-release@v1
        with:
          tag_name: service_data-${{ steps.metadata.outputs.commit_hash }}
          name: Service Data - ${{ steps.metadata.outputs.date }} (${{ steps.metadata.outputs.commit_hash }})
          body: |
            Automated service data release for ${{ steps.metadata.outputs.date }}
                - Generated on: ${{ steps.metadata.outputs.date }} at ${{ steps.metadata.outputs.time }} EST
                - Git Commit: ${{ steps.metadata.outputs.commit_hash }}
            Contains:
              - Live data CSVs in the root directory
              - Snapshots stored in snapshots_YYYY-MM-DD/ directories
          files: |
            outputs/service_data.sqlite
            live_data_release/**
            snapshots_release/**
          make_latest: true
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      # Cleanup
      - name: Cleanup
        run: rm -rf outputs inputs snapshots_release live_data_release
